{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def textParser(text):\n",
    "    \n",
    "    import re\n",
    "    regEx = re.compile(r'[^a-zA-Z]|\\d')  \n",
    "    words = regEx.split(text)\n",
    "    words = [word.lower() for word in words if len(word) > 0]\n",
    "    return words\n",
    "\n",
    "def loadSMSData(fileName):\n",
    "    \n",
    "    f = open(fileName)\n",
    "    classCategory = []  \n",
    "    smsWords = []\n",
    "    for line in f.readlines():\n",
    "        linedatas = line.strip().split('\\t')\n",
    "        if linedatas[0] == 'lie':\n",
    "            classCategory.append(0)\n",
    "        elif linedatas[0] == 'true':\n",
    "            classCategory.append(1)\n",
    "        words = textParser(linedatas[1])\n",
    "        smsWords.append(words)\n",
    "    return smsWords, classCategory\n",
    "\n",
    "\n",
    "def createVocabularyList(smsWords):\n",
    "    \n",
    "    vocabularySet = set([])\n",
    "    for words in smsWords:\n",
    "        vocabularySet = vocabularySet | set(words)\n",
    "    vocabularyList = list(vocabularySet)\n",
    "    return vocabularyList\n",
    "\n",
    "def getVocabularyList(fileName):\n",
    "    fr = open(fileName)\n",
    "    vocabularyList = fr.readline().strip().split('\\t')\n",
    "    fr.close()\n",
    "    return vocabularyList\n",
    "\n",
    "def setOfWordsToVecTor(vocabularyList, smsWords):\n",
    "    \n",
    "    vocabMarked = [0] * len(vocabularyList)\n",
    "    for smsWord in smsWords:\n",
    "        if smsWord in vocabularyList:\n",
    "            vocabMarked[vocabularyList.index(smsWord)] += 1\n",
    "    return vocabMarked\n",
    "\n",
    "def setOfWordsListToVecTor(vocabularyList, smsWordsList):\n",
    "    \n",
    "    vocabMarkedList = []\n",
    "    for i in range(len(smsWordsList)):\n",
    "        vocabMarked = setOfWordsToVecTor(vocabularyList, smsWordsList[i])\n",
    "        vocabMarkedList.append(vocabMarked)\n",
    "    return vocabMarkedList\n",
    "\n",
    "def trainingNaiveBayes(trainMarkedWords, trainCategory):\n",
    "\n",
    "    numTrainDoc = len(trainMarkedWords)\n",
    "    numWords = len(trainMarkedWords[0])\n",
    "    pSpam = sum(trainCategory) / float(numTrainDoc)\n",
    "    wordsInlieNum = np.ones(numWords)\n",
    "    wordsInTrueNum = np.ones(numWords)\n",
    "    lieWordsNum = 2.0\n",
    "    TrueWordsNum = 2.0\n",
    "    for i in range(0, numTrainDoc):\n",
    "        if trainCategory[i] == 1:  \n",
    "            WordsInlieNum += trainMarkedWords[i]\n",
    "            lieWordsNum += sum(trainMarkedWords[i])  \n",
    "        else:\n",
    "            wordsTrueNum += trainMarkedWords[i]\n",
    "            TrueWordsNum += sum(trainMarkedWords[i])\n",
    "\n",
    "    pWordslie = np.log(WordsInlieNum / lieWordsNum)\n",
    "    pWordsTrue = np.log(wordsInTrueNum / TrueWordsNum)\n",
    "    return pWordsTrue, pWordslie, pLie\n",
    "\n",
    "def getTrainedModelInfo():\n",
    "    \n",
    "    vocabularyList = getVocabularyList('C:/Users/hp 850/Desktop/vocabularyList.txt')\n",
    "    pWordsTrue = np.loadtxt('C:/Users/hp 850/Desktop/pWordsTrue.txt', delimiter='\\t')\n",
    "    pWordslie = np.loadtxt('C:/Users/hp 850/Desktop/pWordslie.txt', delimiter='\\t')\n",
    "    fr = open('C:/Users/hp 850/Desktop/pLie.txt')\n",
    "    pLie = float(fr.readline().strip())\n",
    "    fr.close()\n",
    "    return vocabularyList, pWordsTrue, pWordslie, pLie\n",
    "\n",
    "def classify(vocabularyList, pWordsTrue, pWordslie, pLie, testWords):\n",
    "    \n",
    "    testWordsCount = setOfWordsToVecTor(vocabularyList, testWords)\n",
    "    testWordsMarkedArray = np.array(testWordsCount)\n",
    "    p1 = sum(testWordsMarkedArray * pWordsSpamicity) + np.log(pLie)\n",
    "    p0 = sum(testWordsMarkedArray * pWordsHealthy) + np.log(1 - pLie)\n",
    "    if p1 > p0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bayes\n",
      "  Downloading bayes-0.1.1.tar.gz (3.7 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: bayes\n",
      "  Building wheel for bayes (setup.py): started\n",
      "  Building wheel for bayes (setup.py): finished with status 'done'\n",
      "  Created wheel for bayes: filename=bayes-0.1.1-py3-none-any.whl size=5532 sha256=8c86f08c1062c945fa1a90fb123479772b5c37a9c6b2be218b85e59d5dd0eb61\n",
      "  Stored in directory: c:\\users\\hp 850\\appdata\\local\\pip\\cache\\wheels\\8b\\e1\\33\\bd265d7768a8f78d2ca909f6a70c9bfb334623942e3709cf3b\n",
      "Successfully built bayes\n",
      "Installing collected packages: bayes\n",
      "Successfully installed bayes-0.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip  install  bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import SimpleNavieBayes.NavieBayes as naiveBayes\n",
    "\n",
    "filename = \"C:/Users/hp 850/Desktop/traning.txt\"\n",
    "smsWords, classLables = naiveBayes.loadSMSData(filename)\n",
    "vocabularyList = naiveBayes.createVocabularyList(smsWords)\n",
    "print (\"Generate corpus!\")\n",
    "trainMarkedWords = naiveBayes.setOfWordsListToVecTor(vocabularyList, smsWords)\n",
    "print (\"Data marking is complete!\")\n",
    "trainMarkedWords = np.array(trainMarkedWords)\n",
    "print (\"The data is converted into a matrix!\")\n",
    "pWordslie, pWordsTrue, pLie = naiveBayes.trainingNaiveBayes(trainMarkedWords, classLables)\n",
    "print ('pLie:', pLie)\n",
    "fpLie = open('C:/Users/hp 850/Desktop/pLie.txt', 'w')\n",
    "Lie = pLie.__str__()\n",
    "fpLie.write(Lie)\n",
    "fpLie.close()\n",
    "fw = open('C:/Users/hp 850/Desktop/vocabularyList.txt', 'w')\n",
    "for i in range(len(vocabularyList)):\n",
    "    fw.write(vocabularyList[i] + '\\t')\n",
    "fw.flush()\n",
    "fw.close()\n",
    "np.savetxt('C:/Users/hp 850/Desktop/vocabularyList.txt', pWordsSpamicity, delimiter='\\t')\n",
    "np.savetxt('C:/Users/hp 850/Desktop/pWordsTrue.txt', pWordsHealthy, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleNavieBayes.NavieBayes as naiveBayes\n",
    "import random\n",
    "import numpy as np\n",
    "def simpleTest():\n",
    "    vocabularyList, pWordslie, pWordsTrue, pLie = \\\n",
    "        naiveBayes.getTrainedModelInfo()\n",
    "    filename = 'C:/Users/hp 850/Desktop/testing.txt'\n",
    "    smsWords, classLables = naiveBayes.loadSMSData(filename)\n",
    "    smsType = naiveBayes.classify(vocabularyList, pWordsTrue, pWordslie, pLie, smsWords[0])\n",
    "    print (smsType)\n",
    "\n",
    "def testClassifyErrorRate():\n",
    "    filename = 'C:/Users/hp 850/Desktop/traning.txt'\n",
    "    smsWords, classLables = naiveBayes.loadSMSData(filename)\n",
    "    testWords = []\n",
    "    testWordsType = []\n",
    "    testCount = 1000\n",
    "    for i in range(testCount):\n",
    "        randomIndex = int(random.uniform(0, len(smsWords)))\n",
    "        testWordsType.append(classLables[randomIndex])\n",
    "        testWords.append(smsWords[randomIndex])\n",
    "        del (smsWords[randomIndex])\n",
    "        del (classLables[randomIndex])\n",
    "\n",
    "    vocabularyList = naiveBayes.createVocabularyList(smsWords)\n",
    "    print (\"Generate corpus!\")\n",
    "    trainMarkedWords = naiveBayes.setOfWordsListToVecTor(vocabularyList, smsWords)\n",
    "    print (\"Data marking is complete!\")\n",
    "    trainMarkedWords = np.array(trainMarkedWords)\n",
    "    print (\"The data is converted into a matrix!\")\n",
    "    pWordsTrue, pWordslie, pLie = naiveBayes.trainingNaiveBayes(trainMarkedWords, classLables)\n",
    "    errorCount = 0.0\n",
    "    for i in range(testCount):\n",
    "        smsType = naiveBayes.classify(vocabularyList, pWordsTrue, pWordslie, pLie, testWords[i])\n",
    "        print ('Forecast category:', smsType, 'Actual category:', testWordsType[i])\n",
    "        if smsType != testWordsType[i]:\n",
    "            errorCount += 1\n",
    "    print ('Number of errors:', errorCount, 'Error rate:', errorCount / testCount)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    testClassifyErrorRate()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2524ad928b6673c884538188082f6f687585d800af59c407863e8e96f412705c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
